{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c47f45c4-4c88-4d64-a5a4-08a256a25d2a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd548230-9bf4-4f37-9cc5-8c249d57a2b1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base_dir = pathlib.Path().cwd().parent\n",
    "data_dir = base_dir / 'data' / 'raw'\n",
    "processed_data_dir = base_dir / 'data' / 'processed'\n",
    "\n",
    "RETWEET_GRAPH_FILENAME = 'lcc_retweet.gml'\n",
    "USER_LABELS_FILENAME = 'lcc_retweet_labels.npy'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f51ec74a-0cc1-495e-8e03-cf2f3fbe76c4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "retweet_network_lcc = nx.read_graphml(processed_data_dir / RETWEET_GRAPH_FILENAME)\n",
    "user_labels = np.load(processed_data_dir / USER_LABELS_FILENAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f352f8-d5d2-4bad-9a60-c3ed8dd21347",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Split dataset in training-validation-test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "950e3ae8-8380-4769-b0cd-7434aa20fc32",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tr_perc, val_perc, test_perc = .6, .1, .3\n",
    "user_idxs, num_nodes = np.array(range(len(user_labels))), len(user_labels)\n",
    "tr_node_ids, test_node_ids = train_test_split(user_idxs, train_size=0.6, test_size=0.3, stratify=user_labels)\n",
    "val_node_ids = np.delete(range(user_labels.shape[0]), np.concatenate([tr_node_ids, test_node_ids]))\n",
    "\n",
    "assert (tr_node_ids.shape[0] + val_node_ids.shape[0] + test_node_ids.shape[0]) == num_nodes\n",
    "assert np.intersect1d(tr_node_ids, np.concatenate([val_node_ids, test_node_ids])).shape[0] == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7b28834-efb1-4eca-aca2-14239c48adf1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Unify training and validation for unsupervised baselines\n",
    "val_for_unsupervised_node_ids = np.concatenate([tr_node_ids, val_node_ids])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fc4cc3-515e-4a01-9842-2162f5241e5f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2604b0-1bf8-4c81-8bb5-5756d103eea3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Baseline method 1: Edge filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d428eba-7506-4236-a65c-e24a8d0bc3f9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c24dd3d5954fa6b76c6470fbb35863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "node_ids_list = list(retweet_network_lcc.nodes())\n",
    "# Relabel each node from 0 to N-1\n",
    "node_remapping = {node_ids_list[i]: i for i in range(len(node_ids_list))}\n",
    "retweet_network_lcc = nx.relabel_nodes(retweet_network_lcc, node_remapping)\n",
    "\n",
    "# Make edge weights of float type\n",
    "for u,v,d in retweet_network_lcc.edges(data=True):\n",
    "    d['weight'] = float(d['weight'])\n",
    "\n",
    "weights_list = [attrs[\"weight\"] for _, _, attrs in retweet_network_lcc.edges(data=True)]\n",
    "unique_weights = sorted(list(set(weights_list)))\n",
    "\n",
    "predicted_labels_list = []\n",
    "# Perform different predictions based on different thresholds\n",
    "for weight_percentile in tqdm(np.arange(0, 100, 0.5)):\n",
    "    weight_threshold = np.percentile(weights_list, weight_percentile)\n",
    "    G = retweet_network_lcc.copy()\n",
    "    predicted_labels = np.full(shape=G.number_of_nodes(), fill_value=1)\n",
    "    G.remove_edges_from([(a,b) for a, b, attrs in G.edges(data=True) if float(attrs[\"weight\"]) <= weight_threshold])\n",
    "    legitimate_users = [int(i) for i in nx.isolates(G)]\n",
    "    if len(legitimate_users) > 0:\n",
    "        predicted_labels[legitimate_users] = 0\n",
    "    predicted_labels_list.append(np.copy(predicted_labels))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c16079-5888-4958-b229-d45159b5e48d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Select best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cbedb19-5956-4956-b46a-0167b47cd9d4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef2c3f4713847239a10834c0a81f6d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_dict = {'f1_macro': [], \n",
    "                'f1_micro': [], \n",
    "                'accuracy': [],\n",
    "                'precision': []}\n",
    "for i in tqdm(range(len(predicted_labels_list))):\n",
    "    metrics_dict['f1_macro'].append(metrics.f1_score(user_labels[val_for_unsupervised_node_ids], \n",
    "                                                     predicted_labels_list[i][val_for_unsupervised_node_ids], average='macro'))\n",
    "    metrics_dict['f1_micro'].append(metrics.f1_score(user_labels[val_for_unsupervised_node_ids], \n",
    "                                                     predicted_labels_list[i][val_for_unsupervised_node_ids], average='micro'))\n",
    "    metrics_dict['accuracy'].append(metrics.accuracy_score(user_labels[val_for_unsupervised_node_ids], \n",
    "                                                           predicted_labels_list[i][val_for_unsupervised_node_ids]))\n",
    "    metrics_dict['precision'].append(metrics.precision_score(user_labels[val_for_unsupervised_node_ids], \n",
    "                                                             predicted_labels_list[i][val_for_unsupervised_node_ids]))\n",
    "\n",
    "VAL_METRIC = 'f1_macro' # f1_macro f1_micro accuracy precision\n",
    "best_val_threshold = np.argmax(metrics_dict[VAL_METRIC])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41272b13-fd35-4e9b-a804-82f0afc67fbe",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f01b8787-2a6a-4a9d-baef-2722d5dbd840",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge filtering method result on test set:\n",
      "{'f1_macro': 0.7554690820229495, 'f1_micro': 0.7559009786989063, 'accuracy': 0.7559009786989062, 'precision': 0.8076923076923077}\n"
     ]
    }
   ],
   "source": [
    "test_metrics_edge_filtering_dict = {'f1_macro': None, \n",
    "                                    'f1_micro': None, \n",
    "                                    'accuracy': None,\n",
    "                                    'precision': None}\n",
    "\n",
    "test_metrics_edge_filtering_dict['f1_macro'] = metrics.f1_score(user_labels[test_node_ids], \n",
    "                                                     predicted_labels_list[best_val_threshold][test_node_ids], average='macro')\n",
    "test_metrics_edge_filtering_dict['f1_micro'] = metrics.f1_score(user_labels[test_node_ids], \n",
    "                                                     predicted_labels_list[best_val_threshold][test_node_ids], average='micro')\n",
    "test_metrics_edge_filtering_dict['accuracy'] = metrics.accuracy_score(user_labels[test_node_ids], \n",
    "                                                     predicted_labels_list[best_val_threshold][test_node_ids])\n",
    "test_metrics_edge_filtering_dict['precision'] = metrics.precision_score(user_labels[test_node_ids], \n",
    "                                                     predicted_labels_list[best_val_threshold][test_node_ids])\n",
    "\n",
    "print('Edge filtering method result on test set:')\n",
    "print(test_metrics_edge_filtering_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa7089d-f202-4db4-8188-35f2a429df35",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Baseline method 2: Node pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3e697c9-6ea1-4709-9291-fdc57714bb0d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01990bb3d87741088fcfcae3f4097504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5788 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "centrality_values = nx.eigenvector_centrality(retweet_network_lcc)\n",
    "# Transform into a list\n",
    "centrality_val_list = [-1]*retweet_network_lcc.number_of_nodes()\n",
    "for node_id in tqdm(centrality_values):\n",
    "    centrality_val_list[node_id] = centrality_values[node_id]\n",
    "centrality_val_list = np.array(centrality_val_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2ed759e-12bb-476b-bb87-b0dedef07235",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e42e75e4864a96a0e53468e3ceada2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_labels_list = []\n",
    "for percentile in tqdm(np.arange(0, 100, 0.5)):\n",
    "    centrality_threshold = np.percentile(centrality_val_list, percentile)\n",
    "    predicted_labels = np.full(shape=retweet_network_lcc.number_of_nodes(), fill_value=1)\n",
    "    coordinated_users = np.where(centrality_val_list <= centrality_threshold)[0]\n",
    "    predicted_labels[coordinated_users] = 0\n",
    "    predicted_labels_list.append(np.copy(predicted_labels))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9265f0-f3fc-49a9-9771-eda6f1ae9aa8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Select best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f994c95f-9dc5-46e9-a24b-4e804476c26a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e9953f73194df49ec7875785da649a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_dict = {'f1_macro': [], \n",
    "                'f1_micro': [], \n",
    "                'accuracy': [],\n",
    "                'precision': []}\n",
    "for i in tqdm(range(len(predicted_labels_list))):\n",
    "    metrics_dict['f1_macro'].append(metrics.f1_score(user_labels[val_for_unsupervised_node_ids], \n",
    "                                                     predicted_labels_list[i][val_for_unsupervised_node_ids], average='macro'))\n",
    "    metrics_dict['f1_micro'].append(metrics.f1_score(user_labels[val_for_unsupervised_node_ids], \n",
    "                                                     predicted_labels_list[i][val_for_unsupervised_node_ids], average='micro'))\n",
    "    metrics_dict['accuracy'].append(metrics.accuracy_score(user_labels[val_for_unsupervised_node_ids], \n",
    "                                                           predicted_labels_list[i][val_for_unsupervised_node_ids]))\n",
    "    metrics_dict['precision'].append(metrics.precision_score(user_labels[val_for_unsupervised_node_ids], \n",
    "                                                             predicted_labels_list[i][val_for_unsupervised_node_ids]))\n",
    "VAL_METRIC = 'f1_macro' # f1_macro f1_micro accuracy precision\n",
    "best_val_threshold = np.argmax(metrics_dict[VAL_METRIC])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd01178f-f534-4214-ac03-7369f221e5f7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ada11f4-992d-4529-9027-4ec9b4d12953",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node pruning method result on test set:\n",
      "{'f1_macro': 0.7910356789973291, 'f1_micro': 0.7921704087507196, 'accuracy': 0.7921704087507196, 'precision': 0.823658269441402}\n"
     ]
    }
   ],
   "source": [
    "test_metrics_node_pruning_dict = {'f1_macro': None, \n",
    "                                    'f1_micro': None, \n",
    "                                    'accuracy': None,\n",
    "                                    'precision': None}\n",
    "\n",
    "test_metrics_node_pruning_dict['f1_macro'] = metrics.f1_score(user_labels[test_node_ids], \n",
    "                                                     predicted_labels_list[best_val_threshold][test_node_ids], average='macro')\n",
    "test_metrics_node_pruning_dict['f1_micro'] = metrics.f1_score(user_labels[test_node_ids], \n",
    "                                                     predicted_labels_list[best_val_threshold][test_node_ids], average='micro')\n",
    "test_metrics_node_pruning_dict['accuracy'] = metrics.accuracy_score(user_labels[test_node_ids], \n",
    "                                                     predicted_labels_list[best_val_threshold][test_node_ids])\n",
    "test_metrics_node_pruning_dict['precision'] = metrics.precision_score(user_labels[test_node_ids], \n",
    "                                                     predicted_labels_list[best_val_threshold][test_node_ids])\n",
    "\n",
    "print('Node pruning method result on test set:')\n",
    "print(test_metrics_node_pruning_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91154c75-bf00-4d00-9335-11c09eed89ac",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Supervised method 1: Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02b13f8c-34c9-4f93-bd27-dc1f22dca124",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from node2vec import Node2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e784c1e9-1897-462d-b61c-043d319248a8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740e47fe8d504b0f821cc3faabb86a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/5788 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 2/2 [00:01<00:00,  1.66it/s]\n",
      "Generating walks (CPU: 2): 100%|██████████| 2/2 [00:01<00:00,  1.67it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "Generating walks (CPU: 7): 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "Generating walks (CPU: 8): 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 32\n",
    "# Precompute probabilities and generate walks - **ON WINDOWS ONLY WORKS WITH workers=1**\n",
    "node2vec = Node2Vec(retweet_network_lcc, \n",
    "                    dimensions=hidden_dim, \n",
    "                    walk_length=5, \n",
    "                    num_walks=10, \n",
    "                    workers=8) \n",
    "\n",
    "# Embed nodes\n",
    "model = node2vec.fit(window=8, min_count=1, batch_words=4)  # Any keywords acceptable by gensim.Word2Vec can be passed, `dimensions` and `workers` are automatically passed (from the Node2Vec constructor)\n",
    "node_embeddings_node2vec = np.full(shape=(retweet_network_lcc.number_of_nodes(), hidden_dim),fill_value=None)\n",
    "for node_id in retweet_network_lcc.nodes():\n",
    "    node_embeddings_node2vec[int(node_id)] = model.wv[node_id]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d65cfdb-bbc5-4b9d-ba9e-59cbaacaa40e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a6e15d1-ede9-4962-982a-fb8c0c896a0b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6ad767b-c3b3-4ced-8ff0-482e17f2aae2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node2Vec method result on test set:\n",
      "{'f1_macro': 0.909159541714494, 'f1_micro': 0.9101899827288429, 'accuracy': 0.9101899827288429, 'precision': 0.9103092783505154, 'roc_auc': 0.9739134507306108}\n"
     ]
    }
   ],
   "source": [
    "node_classifier = LogisticRegression()\n",
    "node_classifier.fit(node_embeddings_node2vec[tr_node_ids], user_labels[tr_node_ids])\n",
    "test_logits = node_classifier.predict_proba(node_embeddings_node2vec[test_node_ids])[:, 1]\n",
    "test_pred = node_classifier.predict(node_embeddings_node2vec[test_node_ids])\n",
    "\n",
    "test_metrics_node2vec_dict = {'f1_macro': None, \n",
    "                              'f1_micro': None, \n",
    "                              'accuracy': None,\n",
    "                              'precision': None,\n",
    "                              'roc_auc': None}\n",
    "\n",
    "test_metrics_node2vec_dict['f1_macro'] = metrics.f1_score(user_labels[test_node_ids], \n",
    "                                                     test_pred, average='macro')\n",
    "test_metrics_node2vec_dict['f1_micro'] = metrics.f1_score(user_labels[test_node_ids], \n",
    "                                                     test_pred, average='micro')\n",
    "test_metrics_node2vec_dict['accuracy'] = metrics.accuracy_score(user_labels[test_node_ids], \n",
    "                                                     test_pred)\n",
    "test_metrics_node2vec_dict['precision'] = metrics.precision_score(user_labels[test_node_ids], \n",
    "                                                     test_pred)\n",
    "test_metrics_node2vec_dict['roc_auc'] = metrics.roc_auc_score(user_labels[test_node_ids], \n",
    "                                                                              test_logits)\n",
    "\n",
    "print('Node2Vec method result on test set:')\n",
    "print(test_metrics_node2vec_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8743605-76cf-40c6-9434-f1ec445db035",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Supervised method 2: GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012cabf7-5494-4c8a-b841-435d1d70b457",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfaf4a3-d39c-449d-9cbc-44848d6873ee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799af3dc-101e-4249-ba37-45d52448bc93",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}